---
title: "Landlocked Atlantic Salmon Winooski River Telemetry Weekly Report"
author: "US Fish and Wildlife Service (contact: Jonah_Withers@fws.gov for issues)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive Summary

This document is a weekly summarization of the locations of radio telemetered Atlantic Salmon captured at the Winooski One Dam and released at the canoe launch (Warren and Ruth Beeken Rivershore Preserve) in the Winooski River. The intent of this report is to provide a coarse spatial distribution of tagged fishes' most recent known location. Additionally, this document is intended to provide some quality assurance on receiver performance.  

```{r Data Load and Table, echo = FALSE, include=FALSE}
# Clean house! ----
rm(list = ls()) # Clear environment
gc() # Clear ram

requiredPackages <- c("dplyr", "lubridate", "sf", "sp", 
                      "rgdal", "scales", "ggplot2", "suncalc", 
                      "riverdist", "RODBC", "measurements",
                      "tibble", "knitr", "leaflet", "maps", "doParallel",
                      "data.table", "bit64", "RSQLite", "htmltools", "xts",
                      "dygraphs", "foreach", "readr", "kableExtra", "randomcoloR")

# Function to install any packages not installed
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

# Load packages
ipak(requiredPackages)

# > Connect to access database ####

# Identify channel to connect to database
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=../../Databases/WinooskiSalmonTelemetryDatabase.accdb")

# Look at tables and queries within database
sqlTables(channel)

Tags.0 <- as.data.table(sqlFetch(channel, "qry_FishList")) # Import list of fish info


# Close connection to database
odbcClose(channel)



# Import clean data ----
DF.Clean.0 <- fread("../Tables/PostClean/DF.Clean.csv", 
                     header = TRUE, stringsAsFactors = FALSE)


DF.Clean <- DF.Clean.0 %>% 
  mutate(DetDateTime = with_tz(as.POSIXct(DetDateTime, format = "%Y-%m-%dT%H:%M:%SZ", 
                                  origin = "1970-01-01", 
                                  tz = "UTC"), tzone = "Etc/GMT+4"),
         Release = with_tz(as.POSIXct(Release, format = "%Y-%m-%dT%H:%M:%SZ", 
                              origin = "1970-01-01", 
                              tz = "UTC"), tzone = "Etc/GMT+4"),
         sunrise = with_tz(as.POSIXct(sunrise, format = "%Y-%m-%dT%H:%M:%SZ", 
                              origin = "1970-01-01", 
                              tz = "UTC"), tzone = "Etc/GMT+4"),
         sunset = with_tz(as.POSIXct(sunset, format = "%Y-%m-%dT%H:%M:%SZ", 
                             origin = "1970-01-01", 
                             tz = "UTC"), tzone = "Etc/GMT+4"))




LastDet <- DF.Clean %>%
  arrange(desc(DetDateTime)) %>% 
  distinct(TagID, .keep_all = TRUE)

LastDetSum <- LastDet %>% 
  mutate(ReleaseYear = ifelse(Release < as.Date("2020-01-01"), "2019", "2020")) %>% 
  mutate(River_Segment = factor(case_when(River.Km < 16.51489 ~ "Below Winooski One", 
                              River.Km >= 16.51489 & River.Km < 18.77591 ~ "Below Gorge", 
                              River.Km >= 18.77591 &  River.Km < 29.14046 ~ "Below Essex 19",
                              River.Km >= 29.14046 & River.Km < 49.19853 ~ "Essex 19 to Richmond",
                              River.Km >= 49.19853 & River.Km < 55.81481 ~ "Richmond to Jonesville",
                              River.Km >= 55.81481 ~ "Above Jonesville",
                              TRUE ~  "other"), 
                              levels = c("Above Jonesville", "Richmond to Jonesville", "Essex 19 to Richmond", 
                                         "Below Essex 19", "Below Gorge", "Below Winooski One")))

LastDetSum.1 <- LastDetSum %>% 
  group_by(River_Segment, ReleaseYear) %>% 
  summarise(Salmon1 = n()) %>%
  group_by(ReleaseYear) %>% 
  mutate(Proportion = round(Salmon1 / sum(Salmon1) * 100, 2),
         Salmon = paste(Salmon1, "(", Proportion, " %)")) %>% 
  dplyr::select(River_Segment, ReleaseYear, Salmon) %>% 
  as.data.table() %>% 
  dcast(River_Segment ~ ReleaseYear, value.var = "Salmon")





# Add Trib data ----
# RiverUTM <- line2network(path = "../ArcGIS", #Without Tributaries
#                          layer = "WinooskiRiverKmLine_UTM18", tolerance = 90)
# 
# TribDist <- pointshp2segvert(path = "../ArcGIS",
#                              layer = "Trib_Coords", rivers = RiverUTM)
# 
# for (i in 1:nrow(TribDist)){
#   RiverUTM$mouth$mouth.seg <- 13 # Without tributaries
#   RiverUTM$mouth$mouth.vert <- 1
#   TribDist$River.Km[i] <- mouthdist(TribDist$seg[i], 
#                                     TribDist$vert[i], RiverUTM)
# }
# TribDist <- TribDist %>% 
#   mutate(River.Km.1 = River.Km/1000)
# 
# TribDist.1 <- TribDist %>% 
#   filter( STREAM_ORD > 2) %>%
#   mutate(Trib_Color = case_when(STREAM_ORD == 3 ~ "#6BAED6", # Color code stream by stream_order
#                                 STREAM_ORD == 4 ~ "#2171B5",
#                                 STREAM_ORD == 5 ~ "#08306B",
#                                 TRUE ~ "white"))
```

### Week's Current Fish Locations
```{r RiverSection Table, echo = FALSE, include = TRUE}
kable(LastDetSum.1) %>% 
  kable_classic()
```

```{r 2019 Movement Table, echo = TRUE, include = FALSE, message = FALSE, warning = FALSE}
### Fish Movement on a weekly basis 2019 Salmon
#DF.Clean %>% 
#    filter(Release < as.Date("2020-01-01")) %>% 
#  mutate(SampYear = format(DetDateTime, format = "%Y"), 
#         SampWeek = format(DetDateTime, format = "%W")) %>% 
#  dplyr::select(SampYear, SampWeek, TagID, River.Km) %>% 
#  group_by(TagID, SampWeek) %>% 
#  mutate(DistDiff = round(abs(max(River.Km) - min(River.Km)), 2)) %>% 
#  dplyr::select(TagID, SampWeek, DistDiff) %>% 
#  as.data.table() %>% 
#  dcast(., TagID ~ SampWeek, value.var = "DistDiff", fun.aggregate = max) %>% 
#  mutate_all(funs(ifelse(. == -Inf, "", .))) %>% 
#  mutate_at(vars(-"TagID"), ~ cell_spec(
#        .x, 
#        color = "white",
#        align = "c",
#        background = ifelse(.x > .4, "#009E73", 
#                    ifelse(.x < .4 & .x > -.1, "#D55E00", 
#                           ifelse(.x == "", "yellow", "white"))))) %>%
#  kable(align = 'c',
#        escape = FALSE, 
#        row.names = FALSE, 
#        caption = "If maximum rkm - minimum rkm per week is > 400m cell is #colored green otherwise it is
#        colored red") %>% 
#  kable_styling(row_label_position = l, 
#                fixed_thead = TRUE, 
#                bootstrap_options = c("striped", "hover", "condensed", #"responsive"))
```

### Fish Weekly Movement Table

Difference between the maximum and minimum river kilometer within a given week are calculated for each transmitter. If the difference is > 400 m the cell receivers a green background, if the dfference is < 400 m the cell receivers a red background, and if there are no data available within the given week the cell receivers a yellow background. 
```{r 2020 Movement Table, echo = FALSE, include = TRUE, message = FALSE, warning = FALSE}
DF.Clean %>% 
  filter(Release > as.Date("2020-01-01")) %>% 
  mutate(SampYear = format(DetDateTime, format = "%Y"), 
         SampWeek = format(DetDateTime, format = "%W")) %>% 
  dplyr::select(SampYear, SampWeek, TagID, River.Km) %>% 
  group_by(TagID, SampWeek) %>% 
  mutate(DistDiff = round(abs(max(River.Km) - min(River.Km)), 2)) %>% 
  dplyr::select(TagID, SampWeek, DistDiff) %>% 
  as.data.table() %>% 
  dcast(., TagID ~ SampWeek, value.var = "DistDiff", fun.aggregate = max) %>% 
  mutate_all(funs(ifelse(. == -Inf, "", .))) %>% 
  mutate_at(vars(-"TagID"), ~ cell_spec(
        .x, 
        color = "white",
        align = "c",
        background = ifelse(.x > .4, "#009E73", 
                    ifelse(.x < .4 & .x > -.1, "#D55E00", 
                           ifelse(.x == "", "yellow", "white"))))) %>%
  kable(align = 'c',
        escape = FALSE, 
        row.names = FALSE, 
        caption = "If maximum rkm - minimum rkm per week is > 400m cell is colored green otherwise it is
        colored red") %>% 
  kable_styling(row_label_position = l, 
                fixed_thead = TRUE,
                bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```


```{r Map Build, echo=FALSE, include=TRUE}
# Map most recent detections ----
# set.seed(123)
# pal_seq_mapping <- data.frame(TagID = unique(as.character(LastDet$TagID)),
#                                              color = randomColor(count = length(unique(LastDet$TagID))))
# 
# LastDetSum.0a <- LastDet %>% 
#   left_join(pal_seq_mapping, by = "TagID")
# 
# map <- leaflet(LastDetSum.0a) %>% 
#   addProviderTiles("Esri.WorldImagery", group = "Satellite") %>%
#   addCircleMarkers(lng = ~ Longitude,
#                    lat = ~ Latitude,
#                    color = ~ LastDetSum.0a$color,
#                    popup = ~ TagID,
#                    label = ~ as.character(TagID),
#                    opacity = .75) %>%
#   addScaleBar(position = "bottomleft")
```

### Mapped Locations of 2 weeks

Each fish has a unique color associated with its detected locations
```{r Map, echo = FALSE, include = TRUE}
# for printing the maps
# tagList(map)
```

### River Kilometer for each fish
```{r figurename, echo=FALSE, fig.align = 'center', out.width = '90%'}
files <- list.files(path = "../Figures/PostClean/", 
                    pattern = "*2020.png",
                    full.names = TRUE)

knitr::include_graphics(files)
```



### - Site Quality Assurance -
```{r Creating Beacon Figs, echo=FALSE, include=TRUE, warning = FALSE, message = FALSE}
# QA/QC on beacons ----

# Import receiver files ####
# Read in files for 2020
FilesGMT5 <- list.files(path = "../RawReceiverDownloads/GMTPlus5",
                        pattern = "*.txt") # This creates a list of all files in directory

FilesGMT5a <- as.character(data.frame(Files = FilesGMT5) %>% 
  mutate(FileDate = substr(FilesGMT5, start = 6, stop = 15)) %>% 
  filter(FileDate > (Sys.Date() - 32)) %>%
  dplyr::select(Files) %>% 
  pull())

if(length(FilesGMT5a > 0)){
  df.GMT5Files <- NULL # Create empty shell df to drop files into
  for (i in 1:length(FilesGMT5a)){
    x1 <- fread(paste("../RawReceiverDownloads/GMTPlus5/", FilesGMT5a[i], sep = ""))
    
    x2 <- x1 %>%
      mutate(File = FilesGMT5a[i], # Add file name
             Site = substr(FilesGMT5a[i], start = 1, stop = 3), # Update site to filename site
             timeStamp = as.POSIXct(paste(Date, Time), # Create datetime
                                    format = "%Y-%m-%d %H:%M:%S",
                                    origin="1970-01-01",
                                    tz="Etc/GMT+5"), # Format to GMT+5
             timeStamp = with_tz(timeStamp, tzone = "Etc/GMT+4")) # Convert timestamp to GMT+4 (EST)
    
    df.GMT5Files <- bind_rows(df.GMT5Files, x2)
  }
}

# > Read txt files with GMT +4 ####
FilesGMT4 <- list.files(path = "../RawReceiverDownloads",
                        pattern="*.txt") # This creates a list of all files in directory

FilesGMT4a <- as.character(data.frame(Files = FilesGMT4) %>%
                             mutate(FileDate = substr(FilesGMT4, start = 6, stop = 15)) %>%
                             filter(FileDate > (Sys.Date() - 32)) %>%
                             dplyr::pull(Files)) 

if(length(FilesGMT4a > 0)){
  df.GMT4Files <- NULL
  for (j in 1:length(FilesGMT4a)){
    y1 <- fread(paste("../RawReceiverDownloads/", FilesGMT4a[j], sep = ""))
    
    
    y2 <- y1 %>%
      mutate(File = FilesGMT4a[j], # Add file name
             Site = substr(FilesGMT4a[j], start = 1, stop = 3),  # Update site to filename site
             timeStamp = as.POSIXct(paste(Date, Time), # Create datetime
                                    format = "%Y-%m-%d %H:%M:%S",
                                    origin="1970-01-01",
                                    tz="Etc/GMT+4")) # Format to GMT+4 (EST)
    
    df.GMT4Files <- bind_rows(df.GMT4Files, y2)
  }
}



# Combine dataframes
if(exists("df.GMT4Files", inherits = FALSE) & exists("df.GMT5Files", inherits = FALSE)){
  df.all <- rbind(df.GMT4Files, df.GMT5Files)
  } else if(exists("df.GMT4Files", inherits = FALSE) & !exists("df.GMT5Files", inherits = FALSE)){
    df.all <- df.GMT4Files
    } else {
      df.all <- df.GMT5Files
      }

# > Dedup and filter detections prior to study
df.filtered <- df.all %>%
  distinct(Date, Time, Site, Ant, Freq, Type, Code, Power, .keep_all = TRUE) %>% 
  filter(Date > as.Date("2019-09-01")| !is.na(Date)) 



# Combine time standardized (EST) dataframes
df.timeCorr <- df.filtered %>% 
  mutate(Date = as.Date(format(timeStamp, "%Y-%m-%d")), # Overwrite date with updated dates
         Time = format(timeStamp, "%H:%M:%S"), # Overwrite times with updated times
         DetDateTime = timeStamp, # remove timestamp column
         Site = as.integer(Site)) %>% 
  dplyr::select(-timeStamp)

df.Rec.1 <- df.timeCorr %>%
  mutate(FreqCode = paste0(Freq, 0, " ", Code)) %>% 
  filter(FreqCode == "164.480 25") %>% # Filter frequency we want to increase processing speed
  group_by(FreqCode, Site) %>%
  arrange(Site, DetDateTime) %>%
  mutate(min_lag = difftime(DetDateTime,lag(DetDateTime))) %>% # Creat timelag b/t det.
  ungroup() %>%
  mutate(Site = as.integer(Site)) %>%
  as.data.frame()

df.Rec.1.Sum <- df.Rec.1 %>%
  group_by(Site, Date) %>%
  summarise(detections = n(), Power = mean(Power, na.rm = TRUE)) %>%
  mutate(Date = as.Date(Date))





# Prop. of Det. per Day ----
## Calculate the number of beacons detected on each receiver on a given day. 
### Since they ping every 5 minutes, there should be 288

# Need to add any dates that may be missing for a given receiver. So create dataframe with all dates and stations
## Ultimately need to update this to remove dates past download date
Miss.Dat <- expand.grid(Site = c(seq(from = 101, to = 114, by = 1), 
                                 seq(from = 200, to = 208, by = 1)), 
                        Date = seq(from = as_date(Sys.Date() - 32),
                                   to = as_date(Sys.Date()), by = 1)) %>%
  mutate(detections = 0, Site = as.integer(Site), Date = as.Date(Date))


df.Rec.2 <- df.Rec.1.Sum %>%
  bind_rows(Miss.Dat) %>% # Add any dates not included for each station
  arrange(-detections) %>%
  distinct(Date, Site, .keep_all = TRUE) %>% # Remove stations that have both 0 detections and data present on a given day
  filter(Date > as.Date("2019-09-18")) %>% # Remove data prior to start of study (Ideally this would be the receiver deployment dates)
  mutate(flag = ifelse(detections > 273 &  detections < 302, "Good", "Flag")) %>%
  filter(Date > (Sys.Date() - 32))  # Only look at this past week's data



# > Noise ####
df.Noise <- df.timeCorr %>% 
  mutate(FreqCode = paste0(Freq, 0, " ", Code)) %>% 
  filter(FreqCode != "164.480 25", # Remove beacons
         FreqCode != "164.380 25", # Remove tag drag
         !FreqCode %in% substr(Tags.0$TagID, 6, 16)) %>% 
  mutate(Bin = cut(Power, breaks = seq(-50, -140, -10))) %>% 
  group_by(Bin, Date, Site) %>%
  summarise(NoiseDet = n())





# Plot
Sites <- df.Rec.2 %>% 
  arrange(Site) %>% 
  distinct(Site) %>%
  pull(Site)



# # Plot with GGplot2
# for(i in 1:length(Sites)){
#   tempDat <- df.Rec.2 %>%
#     filter(Site == Sites[i])
#   
#   # plots[[i]]
#   myplot.1 <- tempDat %>%
#     ggplot(aes(x = Date, y = detections)) +
#     geom_point() +
#     scale_x_date(labels = date_format("%Y-%m-%d"), date_breaks = "5 day",
#                  limits = c(min(as.Date(df.Rec.1$Date), na.rm = TRUE), 
#                             max(as.Date(df.Rec.1$Date), na.rm = TRUE))) +
#     geom_hline(yintercept = c(273, 302), 
#                color = "red",
#                size = .1,
#                linetype = "solid") +
#     labs(x = "Date", y = "Daily Detections", title = paste("Site:", Sites[i], sep = ""))+
#     theme_bw() +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   
#   ggsave(filename = paste("../plots/", Sites[i], ".png", sep = ""),
#          plot = myplot.1)
# }







# Dygraphs for RMD ----
# > Beacon count ####
mydyplots.count <- lapply(1:23, function(i) dygraph(xts(x = df.Rec.2 %>%
                                                    filter(Site == Sites[i]) %>%
                                                    ungroup() %>%
                                                    select(Date, detections),
                                                  order.by = df.Rec.2 %>%
                                                    filter(Site == Sites[i]) %>%
                                                    ungroup() %>%
                                                    pull(Date)),
                                              main = paste("Beacon at Station:",
                                                           Sites[i], sep = " ")) %>%
                      dyRangeSelector() %>%
                      dyOptions(drawPoints = TRUE, pointSize = 2, fillGraph = FALSE) %>%
                      dyAxis("y", label = "Number of Detections") %>%
                      dyAxis("x", label = "Date") %>%
                      dyLimit(as.numeric(288), color = "black") %>%
                      dyShading(from = as.numeric(273), to = as.numeric(302),
                                axis = "y", color = "#CCEBD6"))




# > Beacon Power ####
mydyplots.power <- lapply(1:23, function(j) dygraph(xts(x = df.Rec.2 %>% 
                                                    filter(Site == Sites[j]) %>%
                                                    ungroup() %>%
                                                    select(Date, Power),
                                                  order.by = df.Rec.2 %>%
                                                    filter(Site == Sites[j]) %>%  
                                                    ungroup() %>%
                                                    pull(Date)),
                                              main = paste("Beacon at Station:",
                                                           Sites[j], sep = " ")) %>%
                      dyRangeSelector() %>%
                      dyOptions(drawPoints = TRUE, pointSize = 2, fillGraph = FALSE) %>%
                      dyAxis("y", label = "Daily Mean Power (dB)", valueRange = c(-110, -55)) %>%
                      dyAxis("x", label = "Date"))
```

### Beacon time series
The pupose of these plots is to allow users the ability to examine receiver performance on a daily basis by seeing if a tag (beacon) with a known ping rate (five minutes) is being detected at the expected intervals. Since beacons are set to fire every five minutes, the expected number of detections within a day is 288. 
If detections within a given day are less than or greater than 288 the beacon may be out of range, the receiver may not be recording or logging correctly, or there may be an excessive amount of noise that is not being filtered out. 
```{r Plotting Beacon Detections, echo = FALSE, include = TRUE}
# for printing the maps
htmltools::tagList(mydyplots.count)
```


### Site noise
The pupose of these plots is to allow users the ability to examine receiver performance on a daily basis by examining site noise. Noise is considered any detection that does not coincide with a tag ID. This does not include false positives from our tag IDs.
```{r Plotting Noise, echo = FALSE, include = TRUE, warning = FALSE}
for(f in 1:length(Sites)){
  tempdat1 <- df.Noise %>%
    filter(Site == Sites[f])
  
 print(tempdat1 %>%
    ggplot() +
    geom_bar(aes(x = Date, y = NoiseDet, fill = factor(Bin)),
             color = "black",
             stat = 'identity') +
    scale_x_date(labels = date_format("%Y-%m-%d"),
                 date_breaks = "2 day") +
    labs(x = "Date",
         y = "Daily Noise Detections",
         fill = "Power",
         title = paste("Site:", Sites[f], sep = "")) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)))
}
```


### Beacon Power
The pupose of these plots is to allow users the ability to examine mean beacon power on a daily basis. If power of a beacon drastically changes then the site needs to be visited and examined for potentially issues (i.e. check BNC connections, check receiver settings, and check antenna and coax cable for damage).
```{r Plotting Beacon Power, echo = FALSE, include = TRUE, warning = FALSE}
# for printing the maps
htmltools::tagList(mydyplots.power)
```